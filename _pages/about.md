---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello, I'm Ruinan Jin, and I am currently the PhD student focus on medical and trustworthy machine learning. I hold a B.S. (Hon.) in Computer Science from the University of British Columbia (UBC). I have also gained rish industry experiences at Google, Amazon Web Services and Sierra Wireless, working on machine learning research and IoT solutions. Below is a list of my research interests, and I am open to various forms of collaboration. If you share any of these interests, please feel free to reach out!

## Research Directions and Past Experiences

<!-- ### Federated Learning
- **Data Heterogeneity**: personalized and heterogeneous federated learning strategies.
- **Distributed Generative Models**: integration of generative adversarial networks (e.g., StyleGAN2-ADA) into federated settings.
- **Privacy**: differential privacy techniques under federated learning.
- **Data Distillation**: data distillation approaches, such as gradient matching and distribution matching, under federated learning.
- **Federated Recommendation System**: integrate deep learning recommendation model (DLRM) into heterogeneous federated learning for efficient communication.
- **New Regime of Federated Learning**: incorporation of textural gradient features into federated optimization. -->

## Trustworthy Medical AI in Real-World Clinical Settings

My research focuses on building **trustworthy machine learning systems for medicine**, with an emphasis on **foundation and vision-language models (VLMs)**, **medical AI agents**, and **clinical reasoning and dialogue systems** deployed in real-world healthcare settings. I am particularly interested in understanding and improving how medical AI systems behave **beyond simulation**, including their **reliability, safety, fairness, and robustness under real-world clinical use** (e.g., longitudinal decision-making, distribution shift, and heterogeneous patient populations).

A central theme of my work is to **diagnose failure modes in medical AI systems**—such as spurious reasoning, memorization, privacy leakage, bias, and vulnerability to adversarial or distributional perturbations—and to develop **defenses and evaluation methodologies with measurable guarantees**. My research spans both **model development and rigorous evaluation**, with a strong focus on high-impact, sensitive domains such as healthcare.

- **Security & Safety (Failure Modes and Defenses)**  
  Backdoor attacks and defenses in medical and multimodal models; robustness of foundation models and medical AI agents to spurious correlations, adversarial perturbations, and deployment-time shifts; safety-oriented evaluation for clinical reasoning and dialogue systems.

- **Privacy & Data Governance (Trust and Unlearning)**  
  Memorization and data exposure in modern medical VLMs and agents; implications for privacy leakage, fairness, and backdoors; machine unlearning; differential privacy in centralized and federated settings; and privacy-preserving synthetic data generation for sensitive medical domains.

- **Reliability & Generalization (From Simulation to Real World)**  
  Generalization behavior of medical foundation models, VLMs, and federated learning systems under distribution shift, heterogeneous clients, and longitudinal use; robustness-oriented training and evaluation protocols designed to reflect real-world clinical deployment.

- **Fairness & Responsible Evaluation (Clinical Risk Awareness)**  
  Bias measurement and group-fairness constraints in medical foundation models and vision-language systems; fairness-aware benchmarks and evaluation frameworks that connect algorithmic behavior to downstream clinical risk and real-world impact.


<!-- ### Vision-Language Multimodal Models
- **Contrastive Pre-training**: CLIP-family for image-text representation alignment.
- **Generative VL Models**: LLaVA-family for visual question answering, captioning, and multimodal reasoning.
- **Generalization**: in domain and out-of-domain performance benchmark in medical vision-language models.
- **Compositional Learning**: usage of the textual concepts (e.g., concept bottleneck model) to predict intermediate human-interpretable attributes before final decisions. -->


## Open-source Projects
[FairMedFM](https://github.com/FairMedFM/FairMedFM): Collection of fairness evaluation on Foundation Models for medical image analysis.

[MedVLMBench](https://github.com/ubc-tea/MedVLMBench): Collection of medical vision-language models for medical image analysis.

[RVCBench](https://github.com/Nanboy-Ronan/RVCBench): Collection of robustness evaluation on modern TTS and voice clone models.

## Community Service

### Conferences
<ul class="list--grid">
  <li>
    NeurIPS (2025)
    <a class="badge badge--award" href="https://neurips.cc/Conferences/2025/ProgramCommittee#top-reviewer" target="_blank" rel="noopener">
      <i class="fa fa-award" aria-hidden="true"></i>
      Top Reviewer
    </a>
  </li>
  <li>MICCAI (2025)</li>
  
  
</ul>

### Journals
<ul class="list--grid">
<li>
    IEEE Transactions on Medical Imaging
    <a class="badge badge--award" href="" target="_blank" rel="noopener">
      <i class="fa fa-award" aria-hidden="true"></i>
      Distinguished Reviewer (Bronze)
    </a>
  </li>
  <li>IEEE Transactions on Pattern Analysis and Machine Intelligence</li>
  <li>IEEE Transactions on Neural Networks and Learning Systems</li>
  <li>IEEE Journal of Biomedical and Health Informatics</li>
  <li>IEEE Transactions on Artificial Intelligence</li>
  <li>Medical Image Analysis</li>
  <li>Neural Networks</li>
  <li>Pattern Recognition</li>
  
</ul>
